
import os
import typing as tp
import math
import pathlib
import json
import random
import itertools
import logging
import multiprocessing

import torch
import torchaudio
import resampy
import numpy
import librosa
import matplotlib.pyplot as plt

from . import transforms

from copy import deepcopy
from itertools import accumulate
from bisect import bisect_left

def plot_partition(x : numpy.ndarray,
                   partitions : tp.List[tp.Tuple[object]]) -> plt.Figure:
    """
    Parameters
    ----------
    x : numpy.Array
        an Array shaped (C, L) where C is the number of sources and L is waveform length
    partitions :
        list of partitions
    """

    pos_dict = {tuple(range(x.shape[0])): (0, 0)}
    for p0, p1, _ in partitions:
        pall = tuple(sorted(p0+p1))
        row, col = pos_dict[pall]
        pos_dict[tuple(p0)] = (row, col+1)
        pos_dict[tuple(p1)] = (row+len(p0), col+1)

    nrows = max(map(lambda k: k[0], pos_dict.values())) + 1
    ncols = max(map(lambda k: k[1], pos_dict.values())) + 1

    # build spectrograms
    S = numpy.abs(numpy.stack([librosa.stft(y) for y in x], axis=0))
    S_max = numpy.max(numpy.sum(S, axis=0))
    fig, ax = plt.subplots(nrows, ncols)

    for p0, p1, _ in partitions:
        S_p0 = numpy.sum(S[p0], axis=0)
        S_p1 = numpy.sum(S[p1], axis=0)
        S_diff = S_p0 - S_p1
        irow, icol = pos_dict[tuple(sorted(p0+p1))]
        ax[irow, icol].imshow(S_diff,
                              cmap='PiYG',
                              origin='lower',
                              aspect='auto',
                              vmin=-S_max,
                              vmax=S_max)
        ax[irow, icol].set_title(str(tuple(sorted(p0+p1))),
                                 fontsize='x-small',
                                 loc='left')

        if len(p0) == 1:
            irow, icol = pos_dict[tuple(p0)]
            ax[irow, icol].imshow(S_p0,
                                  cmap='PiYG',
                                  origin='lower',
                                  aspect='auto',
                                  vmin=-S_max,
                                  vmax=S_max)
            ax[irow, icol].set_title(str(tuple(p0)),
                                     fontsize='x-small',
                                     loc='left')

        if len(p1) == 1:
            irow, icol = pos_dict[tuple(p1)]
            ax[irow, icol].imshow(-S_p1,
                                  cmap='PiYG',
                                  origin='lower',
                                  aspect='auto',
                                  vmin=-S_max,
                                  vmax=S_max)
            ax[irow, icol].set_title(str(tuple(p1)),
                                     fontsize='x-small',
                                     loc='left')

    for irow, icol in itertools.product(range(nrows), range(ncols)):
        ax[irow, icol].axis('off')

    return fig

def find_partition(x : torch.Tensor,
                   n_fft : int=4096,
                   hop_length : int=1024) -> tp.List[tp.Tuple[object]]:
    """
    Parameters
    ----------
    x : torch.Tensor
        a tensor shaped (C, L), where C is the number of sources and L is waveform length
    n_fft : int
    hop_length : int
    Returns
    -------
    list
        a list contains the partition which is suitable for minimum entropy PIT
    """

    win = torch.hann_window(n_fft, device=x.device)
    S = torch.stft(x, n_fft, hop_length, window=win, return_complex=True).abs()

    in_partition = [list(range(x.shape[0]))]
    out_partitions = []
    while in_partition:
        p = in_partition.pop()
        S_all = torch.sum(S[p], dim=0)
        c_min = None
        e_min = math.inf

        for i in range(1, len(p)):
            for c in map(lambda c: list(c), itertools.combinations(p, i)):
                # construct a mixture of selected sources
                S_c = torch.sum(S[c], dim=0)
                weight = S_c / torch.sum(S_c).clamp(min=1e-6)
                # find entropy of this separation
                prob = S_c / S_all.clamp(min=1e-6)
                e = torch.sum(
                    (-prob*torch.log2(prob.clamp(min=1e-6))
                    -(1-prob)*torch.log2((1-prob).clamp(min=1e-6)))
                    *weight
                ).item()
                if e < e_min:
                    e_min = e
                    c_min = c

        not_c = [d for d in p if d not in c_min]
        cs = sorted(
            [c_min, not_c],
            key=lambda c: torch.sum(S[c]),
            reverse=True
        )
        out_partitions.append((*cs, e_min))
        for c in cs:
            if len(c) > 1:
                in_partition.insert(0, c)

    #return sorted(out_partitions, key=lambda t: t[2], reverse=True)
    return out_partitions


class MEPIT(torch.utils.data.IterableDataset):
    """
    Dataset for ME-PIT
    """

    def __init__(self,
                 source_list : tp.Dict[pathlib.Path, tp.Dict[str, object]],
                 sr : int,
                 duration : float,
                 source_categories : tp.Union[tp.Set[str], tp.List[str]]=None,
                 num_sources : int=None,
                 category_repetition : bool=False,
                 category_weight : tp.Dict[str, float]=None,
                 splits : tp.List[str]=None,
                 scale_range : tp.Tuple[float, float]=(1.0, 1.0),
                 pitch_shift_range : tp.Tuple[float, float]=(1.0, 1.0),
                 time_stretch_range : tp.Tuple[float, float]=(1.0, 1.0),
                 normalize : bool=False
                 ) -> None:
        """
        Parameters
        ----------
        source_list : tp.List[tp.Dict[Path, object]]
            the keys of the dict are path to the .wav files, the value contains followings :
            - category : the category of the source (e.g. vocal, piano)
            - split : the split
            - track : the track identification (if two sources have the same track, the sources are coherent)
        sr : int
        duration : float
        source_categories : tp.List[str] or tp.Set[str]
        num_sources : int
        category_repetition : bool
        splits : tp.List[str]
        scale_range : tp.Tuple[float, float]
        pitch_shift_range : tp.Tuple[float, float]
        time_stretch_range : tp.Tuple[float, float]
        normalize : bool
        """

        if type(source_categories) == list:
            if not source_categories:
                raise ValueError(
                    'source_categories must contain at least one element')
            if num_sources:
                raise ValueError(
                    'num_sources must not be given if source_categories is fed')
            num_sources = len(source_categories)
            category_repetition = num_sources > len(set(source_categories))
        elif type(source_categories) == set:
            if not source_categories:
                raise ValueError(
                    'source_categories must contain at least one element')
            if num_sources is None:
                num_sources = len(source_categories)
        elif type(source_categories) == type(None):
            if not num_sources:
                raise ValueError(
                    'num_sources must be given if source_categories is None')

        # 候補となるパスを生成する
        # 条件項目:
        #   source_categories: Listの場合、その並び順でソースを生成する
        #                      Setの場合、並びは考慮せず組み合わせのみで生成する
        #                      Noneの場合、全カテゴリが選択肢となる
        # モード系項目:
        # category_repetition: Trueの場合、同一カテゴリの繰り返しが許可される
        #                      Falseの場合、繰り返しは許可されない
        source_list = deepcopy(source_list)

        for p, d in list(source_list.items()):
            category = d.get('category', None)
            split = d.get('split', None)
            if type(source_categories) != type(None) \
               and category not in source_categories:
                del source_list[p]
                continue
            if type(splits) != type(None) \
               and split not in splits:
                del source_list[p]
                continue

        # build track_category_dict : category -> path
        track_category_dict = dict()
        for p, d in source_list.items():
            category = d.get('category', None)
            track = d.get('track', None)
            if (track, category) not in track_category_dict:
                track_category_dict[track, category] = set()
            track_category_dict[track, category].add(p)

        # validate track-category dict
        none_track_count = dict()
        for (t, c), ps in track_category_dict.items():
            if t is None:
                none_track_count[c] = none_track_count.get(c, 0) + len(ps)
        if not category_repetition:
            for k in none_track_count:
                none_track_count[k] = 1
        track_set = set(t for t, c in track_category_dict if t is not None)
        for t in track_set:
            track_count = deepcopy(none_track_count)
            for (u, c), ps in track_category_dict.items():
                if u == t:
                    track_count[c] = track_count.get(c, 0) + len(ps)
            if not category_repetition:
                for k in track_count:
                    track_count[k] = 1

            if sum(track_count.values()) < num_sources:
                raise ValueError('track "{t}" contains few sources')
            if type(source_categories) == set and category_repetition:
                for c in source_categories:
                    if track_count.get(c, 0) == 0:
                        raise ValueError(
                            'track "{t}" does not contain category {c}')
            elif type(source_categories) == set and not category_repetition:
                pass
            elif type(source_categories) == list:
                source_cat_count = dict()
                for c in source_categories:
                    source_cat_count[c] = source_cat_count.get(c, 0) + 1
                for c, count in source_cat_count.items():
                    if track_count.get(c, 0) < count:
                        raise ValueError(
                            'track "{t}" contains few sources of category {c}')

        if not track_set:
            if sum(none_track_count.values()) < num_sources:
                raise ValueError('source_list contains few sources')

            if type(source_categories) == set and category_repetition:
                for c in source_categories:
                    if none_track_count.get(c, 0) == 0:
                        raise ValueError(
                            'source_list does not contain category {c}')
            elif type(source_categories) == set and not category_repetition:
                pass
            elif type(source_categories) == list:
                source_cat_count = dict()
                for c in source_categories:
                    source_cat_count[c] = source_cat_count.get(c, 0) + 1
                for c, count in source_cat_count.items():
                    if none_track_count.get(c, 0) < count:
                        raise ValueError(
                            'track "{t}" contains few sources of category {c}')

        self.source_list = deepcopy(source_list)
        self.sr = sr
        self.duration = duration
        self.num_sources = num_sources
        self.source_categories = deepcopy(source_categories)
        self.category_repetition = category_repetition
        self.category_weight = category_weight
        self.splits = deepcopy(splits)
        self.scale_range = scale_range
        self.pitch_shift_range = pitch_shift_range
        self.time_stretch_range = time_stretch_range
        self.normalize = normalize

        self.waveform_length = int(self.sr * self.duration)
        self.track_category_dict = deepcopy(track_category_dict)

    def _sample_source(self,
                       track_category_dict,
                       source_categories) -> tp.Tuple[str, torch.Tensor]:
        """
        returns
        -------
        dict
        'sources': the list of source information dictionary
            each dictionary contains followings:
                'category': the category of the source
                'track': the track of the source
                'path': the source file which the sample came from
        """

        # 候補となるパスを生成する
        # 条件項目:
        #   source_categories: Listの場合、その並び順でソースを生成する
        #                      Setの場合、並びは考慮せず組み合わせのみで生成する
        #                      Noneの場合、全カテゴリが選択肢となる
        # モード系項目:
        # category_repetition: Trueの場合、同一カテゴリの繰り返しが許可される
        #                      Falseの場合、繰り返しは許可されない


        # select category first
        if type(source_categories) == list:
            category = source_categories[i]
        elif type(source_categories) == set:
            category_list = list(set(
                c for t, c in track_category_dict
            ))

        if self.category_weight:
            category_weight = [
                max(self.category_weight.get(c, 0), 0)
                for c in category_list
            ]
            if all(w == 0 for w in category_weight):
                category_weight = [1] * len(category_weight)
            category_weight = list(accumulate(category_weight))
            rvalue = random.uniform(0, category_weight[-1])
            category = category_list[bisect_left(
                category_weight, rvalue)]
        else:
            category = random.choice(category_list)

        # take sample of selected category
        source = random.choice(sum([
            list(ps) for (t, c), ps in track_category_dict.items()
            if c == category
        ], []))
        track = self.source_list[source].get('track', None)
        track_category_dict[track, category].remove(source)
        if len(track_category_dict[track, category]) == 0:
            del track_category_dict[track, category]

        # remove from track_category_dict other than the track or category
        for t, c in list(track_category_dict):
            if track is not None and t is not None and t != track:
                del track_category_dict[(t, c)]
                continue
            if not self.category_repetition and \
               category is not None and c is not None and c == category:
                del track_category_dict[(t, c)]
                continue

        return source

    def sample_source(self) -> tp.List[tp.Dict[str, object]]:
        """
        returns
        -------
        dict
        'sources': the list of source information dictionary
            each dictionary contains followings:
                'category': the category of the source
                'track': the track of the source
                'path': the source file which the sample came from
        """

        # 候補となるパスを生成する
        # 条件項目:
        #   source_categories: Listの場合、その並び順でソースを生成する
        #                      Setの場合、並びは考慮せず組み合わせのみで生成する
        #                      Noneの場合、全カテゴリが選択肢となる
        # モード系項目:
        # category_repetition: Trueの場合、同一カテゴリの繰り返しが許可される
        #                      Falseの場合、繰り返しは許可されない

        sources = []

        track_category_dict = deepcopy(self.track_category_dict)
        source_categories = deepcopy(self.source_categories)
        if source_categories is None:
            source_categories = set(c for t, c in track_category_dict)
        for i in range(self.num_sources):
            # select category first
            if type(source_categories) == list:
                category = source_categories[i]
            elif type(source_categories) == set:
                category_list = list(set(
                    c for t, c in track_category_dict
                ))
                if self.category_weight:
                    category_weight = [
                        max(self.category_weight.get(c, 0), 0)
                        for c in category_list
                    ]
                    if all(w == 0 for w in category_weight):
                        category_weight = [1] * len(category_weight)
                    category_weight = list(accumulate(category_weight))
                    rvalue = random.uniform(0, category_weight[-1])
                    category = category_list[bisect_left(
                        category_weight, rvalue)]
                else:
                    category = random.choice(category_list)

            # take sample of selected category
            source = random.choice(sum([
                list(ps) for (t, c), ps in track_category_dict.items()
                if c == category
            ], []))
            track = self.source_list[source].get('track', None)
            track_category_dict[track, category].remove(source)
            if len(track_category_dict[track, category]) == 0:
                del track_category_dict[track, category]

            # remove from track_category_dict other than the track or category
            for t, c in list(track_category_dict):
                if track is not None and t is not None and t != track:
                    del track_category_dict[(t, c)]
                    continue
                if not self.category_repetition and \
                   category is not None and c is not None and c == category:
                    del track_category_dict[(t, c)]
                    continue

            sources.append(source)

        return sources

    def sample_data(self) -> tp.Dict[str, object]:
        """
        returns
        -------
        dict
        'data': sampled tensors, shape is (c, l) where c is the channel and l is length of the samples
        'sources': the list of source information dictionary
            each dictionary contains followings:
                'category': the category of the source
                'track': the track of the source
                'path': the source file which the sample came from
                'start': start time (in second)
                'end': end time (in second)
                'tf_params': parameters of transforms
        'partitions' : the list of partitions which satisfies minimum entropy pit
            each partition is a tuple contains (source)
        """

        data = torch.empty(self.num_sources, self.waveform_length)
        sources_dicts = []
        sources = self.sample_source()

        track_offset_sec = None
        track_tf_params = dict()

        for path_i, path in enumerate(sources):
            metadata = torchaudio.info(path)
            orig_sr = metadata.sample_rate

            tf_params = dict()

            # get transform parameter
            if track_offset_sec and self.source_list[path].get('track'):
                # set parameter
                tf_params = deepcopy(track_tf_params)
                num_frames = math.ceil(
                    orig_sr * self.duration * tf_params['time_stretch_rate'])
                offset = int(track_offset_sec * orig_sr)

            else:
                # init parameter
                tf_params['time_stretch_rate'] = random.uniform(
                    *self.time_stretch_range)
                tf_params['pitch_shift_rate'] = random.uniform(
                    *self.pitch_shift_range)
                tf_params['scale_start'] = random.uniform(
                    *self.scale_range)
                tf_params['scale_end'] = random.uniform(
                    *self.scale_range)
                tf_params['scale_transition_start'] = random.random()
                tf_params['scale_transition_duration'] = random.random() * \
                    (1 - tf_params['scale_transition_start'])
                tf_params['normalize'] = self.normalize
                num_frames = math.ceil(
                    orig_sr * self.duration * tf_params['time_stretch_rate'])
                offset = int(random.uniform(0, metadata.num_frames - num_frames))
                if offset < 0:
                    offset = 0

            if not track_offset_sec and self.source_list[path].get('track'):
                track_tf_params = deepcopy(tf_params)
                track_offset_sec = offset / orig_sr

            x, _ = torchaudio.load(
                path, frame_offset=offset, num_frames=num_frames
            )
            x = x.mean(dim=0)
            x = transforms.build_transform(
                orig_sr,
                self.sr,
                self.waveform_length,
                **tf_params,
            )(x)

            data[path_i, :] = x
            sources_dicts.append({
                'category': self.source_list[path].get('category', None),
                'track': self.source_list[path].get('track', None),
                'orig_sr': orig_sr,
                'orig_length': num_frames,
                'sr': self.sr,
                'length': self.waveform_length,
                'path': path,
                'start': offset / orig_sr,
                'end': (offset + num_frames) / orig_sr,
                'tf_params': tf_params,
            })

        return data, find_partition(data), sources_dicts

    def _freeze_one(args):
        out_dir, out_path_suffix, MEPIT = args
        out_path = os.path.join(out_dir, out_path_suffix)
        data, partition, metadata = MEPIT.sample_data()
        for m in metadata:
            m['path'] = str(m['path'])
        torch.save(data, out_path)
        return out_path_suffix, partition, metadata

    def freeze(self,
               out_dir : tp.Union[str, pathlib.Path],
               num_samples : int,
               num_process : int=None) -> None:
        logger = logging.getLogger(__name__)
        logger.info('Start freezing MEPIT dataset of %d samples to %s',
                    out_dir,
                    num_samples)

        directory_depth = 0
        ns_copy = num_samples - 1
        while ns_copy > 0:
            directory_depth += 1
            ns_copy = ns_copy // 1000

        out_paths = []

        for si in range(num_samples):
            si_digits = ('{:0' + str(directory_depth*3) + 'd}').format(si)
            out_path_suffix = os.path.join(
                *[
                    si_digits[di*3:(di+1)*3]
                    for di in range(0, directory_depth-1)
                ],
                si_digits + '.pth'
            )
            out_path = os.path.join(out_dir, out_path_suffix)

            if not os.path.exists(os.path.dirname(out_path)):
                os.makedirs(os.path.dirname(out_path), exist_ok=True)

            out_paths.append(out_path_suffix)


        if not num_process is None:
            map_fn = map
        else:
            pool = multiprocessing.Pool(num_process)
            map_fn = pool.imap_unordered

        source_metadata = dict()
        partitions = dict()

        sample_count = 0
        for out_path_suffix, partition, metadata\
            in map_fn(MEPIT._freeze_one, ((out_dir, p, self) for p in out_paths)):

            source_metadata[out_path_suffix] = metadata
            partitions[out_path_suffix] = partition

            sample_count += 1
            if sample_count % 1000 == 0:
                logger.info('file wrote (%d / %d)', si+1, num_samples)

        if not num_process is None:
            pass
        else:
            pool.close()

        with open(os.path.join(out_dir, 'source_metadata.json'), 'w') as fp:
            json.dump(source_metadata, fp)

        with open(os.path.join(out_dir, 'partition_metadata.json'), 'w') as fp:
            json.dump(partitions, fp)

        logger.info('Finish freezing MEPIT dataset to %s', out_dir)


    def __iter__(self) -> tp.Iterator[
            tp.Tuple[torch.Tensor, tp.Dict['str', object], tp.List]]:
        """
        returns
        -------

        Iterator[tp.Tuple[torch.Tensor, tp.List, tp.Dict['str', object]]
        """
        while True:
            yield self.sample_data()

class FrozenMEPIT(torch.utils.data.Dataset):
    def __init__(self,
                 root_dir : tp.Union[pathlib.Path, str],
                 out_partition_metadata : bool=False,
                 out_source_metadata : bool=False) -> None:
        # load source_metadata.json
        sm_path = os.path.join(root_dir, 'source_metadata.json')
        try:
            with open(sm_path, 'r') as fp:
                source_metadata = json.load(fp)
        except OSError as err:
            raise err
        except ValueError as err:
            raise err
        source_metadata = sorted(
            (os.path.join(root_dir, k), v)
            for k, v in source_metadata.items())

        # check all source exist
        lack_files = []
        for s, _ in source_metadata:
            if not os.path.exists(s):
                lack_files.append(s)
        if lack_files:
            raise ValueError(f'paths {lack_files} does not exist')

        # load partition_metadata.json
        pm_path = os.path.join(root_dir, 'partition_metadata.json')
        try:
            with open(pm_path, 'r') as fp:
                partition_metadata = json.load(fp)
        except OSError as err:
            raise err
        except ValueError as err:
            raise err
        partition_metadata = sorted(
            (os.path.join(root_dir, k), v)
            for k, v in partition_metadata.items())

        # check all source exist
        lack_files = []
        for s, _ in partition_metadata:
            if not os.path.exists(s):
                lack_files.append(s)
        if lack_files:
            raise ValueError(f'paths {lack_files} does not exist')

        # check source_metadata and partition_metadata shares same sources
        if [s for s, _ in source_metadata] \
           != [s for s, _ in partition_metadata]:
            raise ValueError(
                'paths of source_metadata and partition_metadata differs')

        self.out_partition_metadata = out_partition_metadata
        self.out_source_metadata = out_source_metadata
        self.source_metadata = source_metadata
        self.partition_metadata = partition_metadata

    def __len__(self) -> int:
        return len(self.source_metadata)

    def __getitem__(self, idx : int) -> \
        tp.Union[torch.Tensor,
                 tp.Tuple[torch.Tensor, tp.Dict],
                 tp.Tuple[torch.Tensor, tp.List],
                 tp.Tuple[torch.Tensor, tp.List, tp.Dict]]:
        path, source_metadata = self.source_metadata[idx]
        _, partition_metadata = self.partition_metadata[idx]
        data = torch.load(path)
        if self.out_partition_metadata and self.out_source_metadata:
            return data, partition_metadata, source_metadata
        elif self.out_partition_metadata and not self.out_source_metadata:
            return data, partition_metadata
        elif not self.out_partition_metadata and self.out_source_metadata:
            return data, source_metadata
        elif not self.out_partition_metadata and not self.out_source_metadata:
            return data
        else:
            return None

    def collate_fn_with_partition_and_source(l):
        return (
            torch.stack([m[0] for m in l], dim=0),
            [m[1] for m in l],
            [m[2] for m in l],
        )

    def collate_fn_with_partition(l):
        return (
            torch.stack([m[0] for m in l], dim=0),
            [m[1] for m in l],
        )

    def collate_fn_with_source(l):
        return (
            torch.stack([m[0] for m in l], dim=0),
            [m[1] for m in l],
        )

    def collate_fn_without_metadata(l):
        return torch.stack([m[0] for m in l], dim=0)


    def get_collate_function(self):
        def collate_function(l):
            if self.out_partition_metadata and self.out_source_metadata:
                return (
                    torch.stack([m[0] for m in l], dim=0),
                    [m[1] for m in l],
                    [m[2] for m in l],
                )
            elif self.out_partition_metadata and not self.out_source_metadata:
                return (
                    torch.stack([m[0] for m in l], dim=0),
                    [m[1] for m in l],
                )
            elif not self.out_partition_metadata and self.out_source_metadata:
                return (
                    torch.stack([m[0] for m in l], dim=0),
                    [m[1] for m in l],
                )
            elif not self.out_partition_metadata and not self.out_source_metadata:
                return torch.stack([m[0] for m in l], dim=0),
            else:
                return None
        return collate_function


